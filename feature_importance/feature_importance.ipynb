{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a787ee",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762704e",
   "metadata": {},
   "source": [
    "With test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530966e-8c71-4fd1-b556-dce22fefb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = \"../data/4_individual_traces/\"\n",
    "leakage_path = \"leakages/\"\n",
    "out_path = \"tops\"\n",
    "scenarios = [\"\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b53ce5-7cdb-41cc-9397-dedeedf53b81",
   "metadata": {},
   "source": [
    "With real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace = \"../data/traffic_captures\"\n",
    "#leakage_path = \"leakages/\"\n",
    "#out_path = \"tops\"\n",
    "#scenarios = [\"configuration00_default\"] # TODO add the scenerio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300b4f1",
   "metadata": {},
   "source": [
    "### Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36920136-5db3-4d48-ad86-ae320a9e3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rf\n",
    "import pickle\n",
    "import extract\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b699eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [00:21<00:00, 18.47it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for scenario in scenarios:\n",
    "    trace_path = os.path.join(trace, scenario)\n",
    "    out_path = os.path.join(leakage_path, scenario)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    extract.main(trace_path, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d3bbb",
   "metadata": {},
   "source": [
    "### Apply random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f4bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(path_to_features, tr_split):\n",
    "    \"\"\"\n",
    "    Prepare monitored data for training and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # load features dataset\n",
    "    #X_tr, Y_tr = load_data(os.path.join(path_to_features, 'train'), \".features\", \" \")\n",
    "    #X_ts, Y_ts = load_data(os.path.join(path_to_features, 'test'), \".features\", \" \")\n",
    "\n",
    "    X, Y = rf.load_data(path_to_features, \".features\", \" \")\n",
    "\n",
    "\n",
    "    return X, Y\n",
    "    \n",
    "# Feature groups mapping\n",
    "feature_groups = {\n",
    "    'pkt_count': [(0, 13)],\n",
    "    'interarrival': [(13, 25)],\n",
    "    'totaltime': [(25, 37)],\n",
    "    'ngram': [(37, 161)],\n",
    "    'transposition': [(161, 765)],\n",
    "    'pkt_distribution': [(2553, 2778)],\n",
    "    'burst': [(2778, 2789)],\n",
    "    \"input_related\": [(2, 3), (4, 5), (7, 8), (9, 10), (12, 13), (21, 25), (33, 37)],\n",
    "    \"output_related\": [(1, 2), (3, 4), (6, 7), (8, 9), (11, 12), (17, 21), (29, 33)],\n",
    "    \"together\": [(1, 3), (3, 5), (6, 8), (8, 10), (11, 13), (17, 25), (29, 37)]\n",
    "}\n",
    "\n",
    "def train_and_evaluate_cv(X, Y, out, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform stratified k-fold cross-validation and evaluate performance across feature groups.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, Y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        X_tr, Y_tr = X[train_idx], Y[train_idx]\n",
    "        X_ts, Y_ts = X[test_idx], Y[test_idx]\n",
    "\n",
    "        for name, ranges in feature_groups.items():\n",
    "            print(f\"Evaluating feature group: {name}\")\n",
    "            X_tr_subset_list = []\n",
    "            X_ts_subset_list = []\n",
    "\n",
    "            for start, end in ranges:\n",
    "                if end > X_tr.shape[1]:  # Ensure indices don't exceed dataset dimensions\n",
    "                    print(f\"Skipping {name} range ({start}, {end}): Feature index out of bounds!\")\n",
    "                    continue\n",
    "\n",
    "                X_tr_subset_list.append(X_tr[:, start:end])\n",
    "                X_ts_subset_list.append(X_ts[:, start:end])\n",
    "\n",
    "            # Merge all feature subsets for this category\n",
    "            if X_tr_subset_list and X_ts_subset_list:\n",
    "                X_tr_subset = np.hstack(X_tr_subset_list)\n",
    "                X_ts_subset = np.hstack(X_ts_subset_list)\n",
    "            else:\n",
    "                print(f\"Skipping {name}: Feature subset has zero features!\")\n",
    "                continue\n",
    "\n",
    "            model = RandomForestClassifier(n_jobs=-1, n_estimators=1000, oob_score=True, random_state=1)\n",
    "            model.fit(X_tr_subset, Y_tr)\n",
    "\n",
    "            pred = model.predict_proba(X_ts_subset)\n",
    "            top_1 = np.mean(np.argmax(pred, axis=1) == Y_ts) * 100\n",
    "            top_2 = np.mean([Y_ts[i] in np.argsort(pred[i])[-2:] for i in range(len(Y_ts))]) * 100\n",
    "            top_5 = np.mean([Y_ts[i] in np.argsort(pred[i])[-5:] for i in range(len(Y_ts))]) * 100\n",
    "\n",
    "            results.append([fold + 1, name, f\"{top_1:.1f}%\", f\"{top_2:.1f}%\", f\"{top_5:.1f}%\"])\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Fold\", \"Features\", \"Top-1\", \"Top-2\", \"Top-5\"])\n",
    "    with open(out, \"wb\") as f:\n",
    "        pickle.dump(results_df, f)\n",
    "\n",
    "    print(f\"Results saved in {out}\")\n",
    "    return results_df\n",
    "\n",
    "def classify(features, out, train=0.8, n_splits=5):\n",
    "    X, Y = load_features(features, train)\n",
    "    print(\"Performing 5-fold cross-validation...\")\n",
    "\n",
    "    results_df = train_and_evaluate_cv(X, Y, out, n_splits)\n",
    "    print(results_df.to_string(index=False))\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd68babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing 5-fold cross-validation...\n",
      "Fold 1/5\n",
      "Evaluating feature group: pkt_count\n",
      "Evaluating feature group: interarrival\n",
      "Evaluating feature group: totaltime\n",
      "Evaluating feature group: ngram\n",
      "Evaluating feature group: transposition\n",
      "Evaluating feature group: pkt_distribution\n",
      "Evaluating feature group: burst\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 2/5\n",
      "Evaluating feature group: pkt_count\n",
      "Evaluating feature group: interarrival\n",
      "Evaluating feature group: totaltime\n",
      "Evaluating feature group: ngram\n",
      "Evaluating feature group: transposition\n",
      "Evaluating feature group: pkt_distribution\n",
      "Evaluating feature group: burst\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 3/5\n",
      "Evaluating feature group: pkt_count\n",
      "Evaluating feature group: interarrival\n",
      "Evaluating feature group: totaltime\n",
      "Evaluating feature group: ngram\n",
      "Evaluating feature group: transposition\n",
      "Evaluating feature group: pkt_distribution\n",
      "Evaluating feature group: burst\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 4/5\n",
      "Evaluating feature group: pkt_count\n",
      "Evaluating feature group: interarrival\n",
      "Evaluating feature group: totaltime\n",
      "Evaluating feature group: ngram\n",
      "Evaluating feature group: transposition\n",
      "Evaluating feature group: pkt_distribution\n",
      "Evaluating feature group: burst\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 5/5\n",
      "Evaluating feature group: pkt_count\n",
      "Evaluating feature group: interarrival\n",
      "Evaluating feature group: totaltime\n",
      "Evaluating feature group: ngram\n",
      "Evaluating feature group: transposition\n",
      "Evaluating feature group: pkt_distribution\n",
      "Evaluating feature group: burst\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Results saved in leakages//.pkl\n",
      " Fold         Features  Top-1  Top-2  Top-5\n",
      "    1        pkt_count 100.0% 100.0% 100.0%\n",
      "    1     interarrival  98.8% 100.0% 100.0%\n",
      "    1        totaltime 100.0% 100.0% 100.0%\n",
      "    1            ngram 100.0% 100.0% 100.0%\n",
      "    1    transposition 100.0% 100.0% 100.0%\n",
      "    1 pkt_distribution 100.0% 100.0% 100.0%\n",
      "    1            burst 100.0% 100.0% 100.0%\n",
      "    1    input_related 100.0% 100.0% 100.0%\n",
      "    1   output_related 100.0% 100.0% 100.0%\n",
      "    1         together 100.0% 100.0% 100.0%\n",
      "    2        pkt_count  98.8% 100.0% 100.0%\n",
      "    2     interarrival  98.8% 100.0% 100.0%\n",
      "    2        totaltime  98.8% 100.0% 100.0%\n",
      "    2            ngram  98.8% 100.0% 100.0%\n",
      "    2    transposition 100.0% 100.0% 100.0%\n",
      "    2 pkt_distribution  98.8% 100.0% 100.0%\n",
      "    2            burst 100.0% 100.0% 100.0%\n",
      "    2    input_related  98.8% 100.0% 100.0%\n",
      "    2   output_related  98.8% 100.0% 100.0%\n",
      "    2         together  98.8% 100.0% 100.0%\n",
      "    3        pkt_count 100.0% 100.0% 100.0%\n",
      "    3     interarrival 100.0% 100.0% 100.0%\n",
      "    3        totaltime 100.0% 100.0% 100.0%\n",
      "    3            ngram 100.0% 100.0% 100.0%\n",
      "    3    transposition  97.5% 100.0% 100.0%\n",
      "    3 pkt_distribution 100.0% 100.0% 100.0%\n",
      "    3            burst 100.0% 100.0% 100.0%\n",
      "    3    input_related 100.0% 100.0% 100.0%\n",
      "    3   output_related 100.0% 100.0% 100.0%\n",
      "    3         together 100.0% 100.0% 100.0%\n",
      "    4        pkt_count 100.0% 100.0% 100.0%\n",
      "    4     interarrival 100.0% 100.0% 100.0%\n",
      "    4        totaltime  98.8% 100.0% 100.0%\n",
      "    4            ngram 100.0% 100.0% 100.0%\n",
      "    4    transposition  98.8% 100.0% 100.0%\n",
      "    4 pkt_distribution 100.0% 100.0% 100.0%\n",
      "    4            burst  98.8% 100.0% 100.0%\n",
      "    4    input_related 100.0% 100.0% 100.0%\n",
      "    4   output_related 100.0% 100.0% 100.0%\n",
      "    4         together 100.0% 100.0% 100.0%\n",
      "    5        pkt_count 100.0% 100.0% 100.0%\n",
      "    5     interarrival  98.8% 100.0% 100.0%\n",
      "    5        totaltime 100.0% 100.0% 100.0%\n",
      "    5            ngram 100.0% 100.0% 100.0%\n",
      "    5    transposition 100.0% 100.0% 100.0%\n",
      "    5 pkt_distribution 100.0% 100.0% 100.0%\n",
      "    5            burst 100.0% 100.0% 100.0%\n",
      "    5    input_related 100.0% 100.0% 100.0%\n",
      "    5   output_related 100.0% 100.0% 100.0%\n",
      "    5         together 100.0% 100.0% 100.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    features = f\"{leakage_path}/{scenario}/\"\n",
    "    out = f\"{out_path}/{scenario}.pkl\"\n",
    "    topn = classify(features, out, train=0.8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11771edc-9591-4464-9dac-bc1492fce2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
