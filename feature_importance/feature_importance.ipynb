{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a787ee",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1845d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = \"../data/traffic_captures\"\n",
    "leakage_path = \"leakages/\"\n",
    "out_path = \"tops\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300b4f1",
   "metadata": {},
   "source": [
    "### Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36920136-5db3-4d48-ad86-ae320a9e3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rf\n",
    "import pickle\n",
    "import extract\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9491d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\"configuration00_default\"] # TODO add the scenerio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b699eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11528/11528 [08:51<00:00, 21.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for scenario in scenarios:\n",
    "    trace_path = os.path.join(trace, scenario)\n",
    "    out_path = os.path.join(leakage_path, scenario)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    extract.main(trace_path, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d3bbb",
   "metadata": {},
   "source": [
    "### Apply random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(path_to_features, tr_split):\n",
    "    \"\"\"\n",
    "    Prepare monitored data for training and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # load features dataset\n",
    "    #X_tr, Y_tr = load_data(os.path.join(path_to_features, 'train'), \".features\", \" \")\n",
    "    #X_ts, Y_ts = load_data(os.path.join(path_to_features, 'test'), \".features\", \" \")\n",
    "\n",
    "    X, Y = rf.load_data(path_to_features, \".features\", \" \")\n",
    "\n",
    "\n",
    "    return X, Y\n",
    "    \n",
    "# Feature groups mapping\n",
    "feature_groups = {\n",
    "    \"input_related\": [(2, 3), (4, 5), (7, 8), (9, 10), (12, 13), (21, 25), (33, 37)],\n",
    "    \"output_related\": [(1, 2), (3, 4), (6, 7), (8, 9), (11, 12), (17, 21), (29, 33)],\n",
    "    \"together\": [(1, 3), (3, 5), (6, 8), (8, 10), (11, 13), (17, 25), (29, 37)]\n",
    "}\n",
    "\n",
    "def train_and_evaluate_cv(X, Y, out, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform stratified k-fold cross-validation and evaluate performance across feature groups.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, Y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        X_tr, Y_tr = X[train_idx], Y[train_idx]\n",
    "        X_ts, Y_ts = X[test_idx], Y[test_idx]\n",
    "\n",
    "        for name, ranges in feature_groups.items():\n",
    "            print(f\"Evaluating feature group: {name}\")\n",
    "            X_tr_subset_list = []\n",
    "            X_ts_subset_list = []\n",
    "\n",
    "            for start, end in ranges:\n",
    "                if end > X_tr.shape[1]:  # Ensure indices don't exceed dataset dimensions\n",
    "                    print(f\"Skipping {name} range ({start}, {end}): Feature index out of bounds!\")\n",
    "                    continue\n",
    "\n",
    "                X_tr_subset_list.append(X_tr[:, start:end])\n",
    "                X_ts_subset_list.append(X_ts[:, start:end])\n",
    "\n",
    "            # Merge all feature subsets for this category\n",
    "            if X_tr_subset_list and X_ts_subset_list:\n",
    "                X_tr_subset = np.hstack(X_tr_subset_list)\n",
    "                X_ts_subset = np.hstack(X_ts_subset_list)\n",
    "            else:\n",
    "                print(f\"Skipping {name}: Feature subset has zero features!\")\n",
    "                continue\n",
    "\n",
    "            model = RandomForestClassifier(n_jobs=-1, n_estimators=1000, oob_score=True, random_state=1)\n",
    "            model.fit(X_tr_subset, Y_tr)\n",
    "\n",
    "            pred = model.predict_proba(X_ts_subset)\n",
    "            top_1 = np.mean(np.argmax(pred, axis=1) == Y_ts) * 100\n",
    "            top_2 = np.mean([Y_ts[i] in np.argsort(pred[i])[-2:] for i in range(len(Y_ts))]) * 100\n",
    "            top_5 = np.mean([Y_ts[i] in np.argsort(pred[i])[-5:] for i in range(len(Y_ts))]) * 100\n",
    "\n",
    "            results.append([fold + 1, name, f\"{top_1:.1f}%\", f\"{top_2:.1f}%\", f\"{top_5:.1f}%\"])\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Fold\", \"Features\", \"Top-1\", \"Top-2\", \"Top-5\"])\n",
    "    with open(out, \"wb\") as f:\n",
    "        pickle.dump(results_df, f)\n",
    "\n",
    "    print(f\"Results saved in {out}\")\n",
    "    return results_df\n",
    "\n",
    "def classify(features, out, train=0.8, n_splits=5):\n",
    "    X, Y = load_features(features, train)\n",
    "    print(\"Performing 5-fold cross-validation...\")\n",
    "\n",
    "    results_df = train_and_evaluate_cv(X, Y, out, n_splits)\n",
    "    print(results_df.to_string(index=False))\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration00_default\n",
      "Performing 5-fold cross-validation...\n",
      "Fold 1/5\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 2/5\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 3/5\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 4/5\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Fold 5/5\n",
      "Evaluating feature group: input_related\n",
      "Evaluating feature group: output_related\n",
      "Evaluating feature group: together\n",
      "Results saved in leakages/configuration00_default/configuration00_default.pkl\n",
      " Fold       Features Top-1 Top-2 Top-5\n",
      "    1  input_related 71.9% 85.1% 95.0%\n",
      "    1 output_related 43.9% 60.9% 81.1%\n",
      "    1       together 70.7% 84.0% 94.8%\n",
      "    2  input_related 72.1% 86.1% 95.1%\n",
      "    2 output_related 44.5% 61.3% 80.8%\n",
      "    2       together 70.2% 84.2% 94.7%\n",
      "    3  input_related 71.9% 85.6% 95.4%\n",
      "    3 output_related 44.0% 60.8% 80.7%\n",
      "    3       together 69.6% 82.7% 94.8%\n",
      "    4  input_related 71.7% 86.2% 95.1%\n",
      "    4 output_related 44.9% 61.0% 82.5%\n",
      "    4       together 68.9% 84.6% 94.8%\n",
      "    5  input_related 71.0% 85.5% 95.3%\n",
      "    5 output_related 43.8% 61.8% 81.3%\n",
      "    5       together 69.3% 84.9% 94.7%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    features = f\"{leakage_path}/{scenario}/\"\n",
    "    out = f\"{out_path}/{scenario}.pkl\"\n",
    "    topn = classify(features, out, train=0.8)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
